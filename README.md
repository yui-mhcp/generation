# :yum: Generative Adversarial Networks (GAN)

## Project structure

```bash
├── custom_architectures/   : custom architectures
├── custom_layers/          : custom layers
├── custom_train_objects/   : custom objects for training
│   ├── callbacks/          : custom callbacks
│   ├── generators/         : custom data generators
│   ├── losses/             : custom losses
│   ├── optimizers/         : custom optimizers / lr schedulers
├── datasets/               : utilities for dataset loading / processing
│   ├── custom_datasets/    : where to save custom datasets processing
├── hparams/                : utility class to define modulable hyper-parameters
├── models/                 : main `BaseModel` subclasses directory
│   ├── generation/         : directory for `BaseGAN` subclasses
├── pretrained_models/      : saving directory for pretrained models
└── utils/
```

See [my data_processing repo](https://github.com/yui-mhcp/data_processing) for more information on the `utils` module and `data processing` features.

See [my base project](https://github.com/yui-mhcp/base_dl_project) for more information on the `BaseModel` class, supported datasets, project extension, ...

## Available models

### Model architectures

Available architectures : 
- `Image GAN` :
    - [Deep Convolutional Generative Adversarial Network (DCGAN)](https://arxiv.org/abs/1511.06434v2)

### Model weights

| Classes   | Conditionned  | Dataset   | Architecture  | Trainer   | Weights   |
| :-------: | :-----------: | :-------: | :-----------: | :-------: | :-------: |
| 10        | No            | `MNIST`   | `DCGAN`       | [me](https://github.com/yui-mhcp) | [Google Drive](https://drive.google.com/drive/folders/1vb41euDXMnF2Ltabhmqc7qPrH-Pxfwjm?usp=sharing)  | 
| 10        | Yes           | `MNIST`   | `DCGAN`       | [me](https://github.com/yui-mhcp) | [Google Drive](https://drive.google.com/drive/folders/12OhduKMgcMwtjtMNkYaI6ZTAdKJWzs46?usp=sharing)  | 

Models must be unzipped in the `pretrained_models/` directory !

## Installation and usage

1. Clone this repository : `git clone https://github.com/yui-mhcp/generation.git`
2. Go to the root of this repository : `cd generation`
3. Install requirements : `pip install -r requirements.txt`
4. Open an example notebook and follow the instructions !


## TO-DO list

- [x] Make the TO-DO list.
- [x] Implement the `GANLoss` class.
- [x] Implement a `GANmetric`.
- [x] Implement the training loop procedure
- [x] Reproduce [tensorflow's DCGAN tutorial](https://www.tensorflow.org/tutorials/generative/dcgan) results
- [x] Implement `label-conditionned` encoder

## What is Generative Adversarial Network

**Generative Adversarial Networks (GANs)** are a special architecture composed of 2 networks : 
- The **generator** which tries to generate realistic outputs
- The **discriminator** which tries to distinguish *real* data from *fake* (generated by the generator) data

Note that I say *output* and not *image* as GAN is a general type of architecture and can be apply to whathever you want and not only to generate images (even if it is the most popular usage of GANs). 

### GAN training procedure

The idea is to train both models simultaneously such that the discriminator will learn *what is a real data* and the generator will try to *flood the discriminator* by producing data it thinks to bereal.

The idea is that the discriminator will lean caracteristics of real data and the generator will lean how to reproduce these caracteristics in order to flood the discriminator.


- Generator : the generator's objective is that the discriminator classifies its data as `true` data. The `target` is therefore that the discriminator predicts `1` and the loss will be a `binary_crossentropy` with `1-values` as target and `discriminator output` as prediction
```python
def generator_loss(fake_scores):
    return tf.reduce_mean(binary_crossentropy(tf.ones_like(fake_scores), fake_scores))
```

- Discriminator : the discriminator's objective has 2 parts : 
    - Classify real data as real (score of 1)
    - Classify fake data as fake (score of 0)
The loss will be the sum of both losses (fake_loss and real_loss) where both are `binary_crossentropy`
```python
def discriminator_loss(true_scores, fake_scores):
    true_loss tf.reduce_mean(binary_crossentropy(tf.ones_like(true_scores), true_scores))
    fake_loss tf.reduce_mean(binary_crossentropy(tf.zeros_like(fake_scores), fake_scores))
    return true_loss + fake_loss
```


### GAN challenges

#### Diversification

This problem appears when the `generator` tends to generate always the same kind of image. Once itfinds how to flood the discriminator, it can tend to reproduce this pattern as much as possible as it has seen that it works. 

This issue mostly appears when the dataset is relatively small which can limit the discriminator learning and make it focus on some caracteristics the generator will massively reproduce. 

#### Stability / cooperation

The main objective of this approach is that the generator will learn from the discriminator : they should collaborate to improve each other progressively. 

However, it is possible that the discriminator outperforms the generator and will never be confused which will make the generator unable to learn. 

Another problem is that after convergence of the generator, the discriminator loss will increase which will make the discriminator unstable. This can lead to a loss of quality in the discriminator decision and make the generator decrease the quality of its generation. 

#### Quality / resolution

Another issue is the  image's size / resolution which cannot be too large because it will be too difficult for the generator to flood the discriminator at the beginning and prevent any learning. 



## Contacts and licence

You can contact [me](https://github.com/yui-mhcp) at yui-mhcp@tutanota.com or on [discord](https://discord.com) at `yui#0732`

The objective of these projects is to facilitate the development and deployment of useful application using Deep Learning for solving real-world problems and helping people. 
For this purpose, all the code is under the [GNU GPL v3 licence](LICENCE)

Furthermore, you **cannot** use any of these projects for commercial purpose without my permission. You can use, modify, distribute and use any of my projects for production as long as you respect the terms of the [licence](LICENCE) and use it for non-commercial purposes (i.e. free applications / research). 

If you use this project in your work, please cite this project to give it more visibility ! :smile:

```
@misc{yui-mhcp
    author  = {yui},
    title   = {A Deep Learning projects centralization},
    year    = {2021},
    publisher   = {GitHub},
    howpublished    = {\url{https://github.com/yui-mhcp}}
}
```

## Notes and references

Tutorials and projects : 
- [tensorflow tutorials](https://www.tensorflow.org/tutorials/generative/dcgan) : contains multiple well-explained tutorials on multiple architectures (`DCGAN`, `Pix2Pix`, ...). 
- [NVIDIA's repository](https://github.com/NVlabs/stylegan2) : official repository for the `StyleGAN2` architecture

Papers : 
- [1] [Generative Adversarial Nets](https://papers.nips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf) : introduction paper to GANs
- [2] [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434v2) : the original `DCGAN` paper
- [3] [Analyzing and Improving the Image Quality of StyleGAN](https://arxiv.org/abs/1912.04958) : the official `StyleGAN2` architecture
- [4] [Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://arxiv.org/abs/1710.10196) : paper for PGGAN which proposes a new approach to solve major GAN challenges
- [5] [MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis](https://arxiv.org/abs/1910.06711v1) : the original MelGAN paper (to show another example of usage for GAN)
